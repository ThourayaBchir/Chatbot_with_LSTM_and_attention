{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tb\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Reshape\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Input, Embedding\n",
    "\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** First part : preparing data *********************************\n",
    "# load dataset, embeddings and define parameters \n",
    "\n",
    "Max_Seq_Length = 20             # try other values  \n",
    "Max_Num_Words = 20000           # tokenization will be restricted to the top Max_Num_Words most common words in the dataset\n",
    "Embedding_Dim = 50              # as we choose glove.6B.50d.txt \n",
    "Validation_Split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings_index dictionaty word:emdedding\n",
      "Found 400000 word vectors.\n",
      "Creating dataset :\n",
      "Found 131 unique tokens.\n",
      "x_train shape (8, 20)\n",
      "y_train shape (8, 20)\n",
      "x_val shape (2, 20)\n",
      "y_val shape (2, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a dictionary \"embeddings_index\" \" mapping each word to its embedding vector \n",
    "print('Creating ''embeddings_index'' dictionaty word:emdedding')\n",
    "embeddings_index = {}\n",
    "with open('data/glove.6B.50d.txt', 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "# Create list of lines of text from the original test file\n",
    "texts=[]\n",
    "with open('text_file.txt', 'r', encoding=\"utf8\") as f:\n",
    "                    for line in f:\n",
    "                        i = line.find('\\n')  # skip \\n\n",
    "                        if 0 < i:\n",
    "                            line = line[:i]\n",
    "                        texts.append(line)\n",
    "\n",
    "\n",
    "# Vectorize the texts samples into a 2D integer tensor \n",
    "# sequences: a list of tokens \n",
    "# word_index: dictionary \n",
    "print(\"Creating dataset :\")\n",
    "t = Tokenizer(num_words=Max_Num_Words)\n",
    "t.fit_on_texts(texts)\n",
    "sequences = t.texts_to_sequences(texts)\n",
    "word_index = t.word_index                                          # word_index will have the indexes for texts nad labels \n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data_all = pad_sequences(sequences, maxlen=Max_Seq_Length)         # Padding sequences into a same length: Max_Seq_Length\n",
    "data = data_all[:np.shape(data_all)[0]//2][:]                      # Splitting data line into 2\n",
    "labels = data_all[np.shape(data_all)[0]//2 :][:]                   # we need a text_file [All first sentences lines] then [All replies lines]\n",
    "\n",
    "\n",
    "# Split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(Validation_Split * data.shape[0])\n",
    "\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n",
    "print(\"x_train shape\",np.shape(x_train))\n",
    "print(\"y_train shape\",np.shape(y_train))\n",
    "print(\"x_val shape\" , np.shape(x_val))\n",
    "print(\"y_val shape\" , np.shape(y_val))\n",
    "\n",
    "\n",
    "#-----------Creating the embedding matrix--------------------\n",
    "# Embeddings matrix (50, 20000) (Embedding_Dim, num_words)\n",
    "\n",
    "num_words = min(Max_Num_Words, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, Embedding_Dim))\n",
    "for word, i in word_index.items():       \n",
    "    if i >= Max_Num_Words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "#-----------Creating the Keras embedding Layer----------------\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "embedding_layer = Embedding(num_words,Embedding_Dim, weights=[embedding_matrix], input_length=Max_Seq_Length, trainable=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** 2nd part : helper functions *********************************\n",
    "\n",
    "\n",
    "# softmax function\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor\n",
    "        axis: Integer, axis along which the softmax normalization is applied\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
    "\n",
    "\n",
    "# Define layers as global variables \n",
    "repeat_tx = RepeatVector(Max_Seq_Length)\n",
    "concatenate_2 = Concatenate(axis=2)\n",
    "dense_10 = Dense(10, activation = \"tanh\")\n",
    "dense_1 = Dense(1, activation = \"relu\") \n",
    "activate_1 = Activation(softmax, name='attention_weights') \n",
    "dot_1 = Dot(axes = 1)\n",
    "Activation_ = Activation('softmax')\n",
    "\n",
    "# one_step_attention function\n",
    "\n",
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    One step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    s_prev = repeat_tx(s_prev)\n",
    "    concat = concatenate_2([ a, s_prev])\n",
    "    e = dense_10(concat)\n",
    "    energies = dense_1(e)\n",
    "    alphas = activate_1(energies)\n",
    "    context = dot_1([alphas, a])\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "# Other functions\n",
    "\n",
    "def value_to_indice(rand_value, vector):\n",
    "    '''\n",
    "    rand_value: a value in the vector type float64\n",
    "    vector: numpay array\n",
    "    return the indice of the first occurence of the value\n",
    "    '''\n",
    "    ind = np.nonzero(vector*1e16 == rand_value*1e16)\n",
    "    \n",
    "    indice_random_value = ind[0]\n",
    "        \n",
    "    return indice_random_value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************** 3nd part : keras model **************************\n",
    "\n",
    "# Defining layers as global variables - to have shared weights \n",
    "n_a = 32  # hidden state dimension for the post attention LSTM cell\n",
    "n_s = 32  # hidden state dimension for the last LSTM cell \n",
    "\n",
    "reshap_ = Reshape((1, n_a,))  \n",
    "post_attention_LSTM_cell = LSTM(n_s, return_state = True)  # Post attention-step LSTM cell\n",
    "output_layer2 = Dense(num_words, activation=softmax) \n",
    "output_linearlayer = Dense(n_a, activation=None)           #  Linear linears \n",
    "output_linearlayer2 = Dense(n_a, activation=None)     \n",
    "last_LSTM_cell = LSTM(n_a, return_state = True)            # Last LSTM cell \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(Tx, Ty, n_a, n_s, Embedding_Dim, num_words):\n",
    "    \"\"\"\n",
    "    Model architecture: Bidirectional LSTM -> attention-step-> Post attention LSTM -> Generative LSTM\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence = Max_Seq_Length\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    Embedding_Dim : Word embeddings dimension\n",
    "    num_words : total number of words\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #m=5 #number examples\n",
    "    x_train = Input(shape=(Max_Seq_Length, ),  batch_shape=(None, Max_Seq_Length))  \n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')   \n",
    "    ss0 = Input(shape=(n_a,), name='ss0') \n",
    "    cc0 = Input(shape=( n_a,), name='cc0')  \n",
    "    s = s0\n",
    "    c = c0\n",
    "    ss = ss0\n",
    "    cc = cc0   \n",
    "    \n",
    "    Tx = Max_Seq_Length\n",
    "    \n",
    "    # outputs initiazing\n",
    "    outputs2 = []\n",
    "    outputs_one_hot =[]\n",
    "\n",
    "    # Embedding layer\n",
    "    x_embed = embedding_layer(x_train)\n",
    "\n",
    "    # Bidirectional LSTM\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(x_embed)  \n",
    "    \n",
    "    # Iterate for Tx steps : attention step -> post attention LSTM \n",
    "    for t in range(Tx):\n",
    "        context = one_step_attention( a, s)\n",
    "        s, _, c = post_attention_LSTM_cell(context, initial_state = [s,c])  \n",
    "    \n",
    "    # Iterate for Ty steps : Generative last LSTM cell\n",
    "    out20 = reshap_(output_linearlayer(s))\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        ss, _, cc = last_LSTM_cell(out20, initial_state = [ss,cc]) \n",
    "        out2 = output_layer2(ss)                                       \n",
    "        out2 = Activation_(out2)\n",
    "        out20 = reshap_(output_linearlayer2(out2))         \n",
    "        outputs2.append(out2)\n",
    "\n",
    "    print(\"outputs2 shape\", np.shape(outputs2[0])) \n",
    "    \n",
    "    # Generating the model\n",
    "    model = Model(inputs= [x_train, s0,c0, ss0, cc0], outputs= outputs2)\n",
    "    \n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs2 shape (?, 132)\n"
     ]
    }
   ],
   "source": [
    "model1 = model(20, 20, n_a, n_s, Embedding_Dim, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 50)       6600        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 20, 64)       21248       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 20, 32)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "                                                                 lstm_1[10][0]                    \n",
      "                                                                 lstm_1[11][0]                    \n",
      "                                                                 lstm_1[12][0]                    \n",
      "                                                                 lstm_1[13][0]                    \n",
      "                                                                 lstm_1[14][0]                    \n",
      "                                                                 lstm_1[15][0]                    \n",
      "                                                                 lstm_1[16][0]                    \n",
      "                                                                 lstm_1[17][0]                    \n",
      "                                                                 lstm_1[18][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 96)       0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[10][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[11][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[12][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[13][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[14][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[15][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[16][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[17][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[18][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[19][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20, 10)       970         concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "                                                                 concatenate_1[10][0]             \n",
      "                                                                 concatenate_1[11][0]             \n",
      "                                                                 concatenate_1[12][0]             \n",
      "                                                                 concatenate_1[13][0]             \n",
      "                                                                 concatenate_1[14][0]             \n",
      "                                                                 concatenate_1[15][0]             \n",
      "                                                                 concatenate_1[16][0]             \n",
      "                                                                 concatenate_1[17][0]             \n",
      "                                                                 concatenate_1[18][0]             \n",
      "                                                                 concatenate_1[19][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "                                                                 dense_1[10][0]                   \n",
      "                                                                 dense_1[11][0]                   \n",
      "                                                                 dense_1[12][0]                   \n",
      "                                                                 dense_1[13][0]                   \n",
      "                                                                 dense_1[14][0]                   \n",
      "                                                                 dense_1[15][0]                   \n",
      "                                                                 dense_1[16][0]                   \n",
      "                                                                 dense_1[17][0]                   \n",
      "                                                                 dense_1[18][0]                   \n",
      "                                                                 dense_1[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 20, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "                                                                 dense_2[10][0]                   \n",
      "                                                                 dense_2[11][0]                   \n",
      "                                                                 dense_2[12][0]                   \n",
      "                                                                 dense_2[13][0]                   \n",
      "                                                                 dense_2[14][0]                   \n",
      "                                                                 dense_2[15][0]                   \n",
      "                                                                 dense_2[16][0]                   \n",
      "                                                                 dense_2[17][0]                   \n",
      "                                                                 dense_2[18][0]                   \n",
      "                                                                 dense_2[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[12][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[13][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[14][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[15][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[16][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[17][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[18][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[19][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 32), (None,  12416       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "                                                                 dot_1[10][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "                                                                 lstm_1[9][2]                     \n",
      "                                                                 dot_1[11][0]                     \n",
      "                                                                 lstm_1[10][0]                    \n",
      "                                                                 lstm_1[10][2]                    \n",
      "                                                                 dot_1[12][0]                     \n",
      "                                                                 lstm_1[11][0]                    \n",
      "                                                                 lstm_1[11][2]                    \n",
      "                                                                 dot_1[13][0]                     \n",
      "                                                                 lstm_1[12][0]                    \n",
      "                                                                 lstm_1[12][2]                    \n",
      "                                                                 dot_1[14][0]                     \n",
      "                                                                 lstm_1[13][0]                    \n",
      "                                                                 lstm_1[13][2]                    \n",
      "                                                                 dot_1[15][0]                     \n",
      "                                                                 lstm_1[14][0]                    \n",
      "                                                                 lstm_1[14][2]                    \n",
      "                                                                 dot_1[16][0]                     \n",
      "                                                                 lstm_1[15][0]                    \n",
      "                                                                 lstm_1[15][2]                    \n",
      "                                                                 dot_1[17][0]                     \n",
      "                                                                 lstm_1[16][0]                    \n",
      "                                                                 lstm_1[16][2]                    \n",
      "                                                                 dot_1[18][0]                     \n",
      "                                                                 lstm_1[17][0]                    \n",
      "                                                                 lstm_1[17][2]                    \n",
      "                                                                 dot_1[19][0]                     \n",
      "                                                                 lstm_1[18][0]                    \n",
      "                                                                 lstm_1[18][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           1056        lstm_1[19][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 32)        0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_5[1][0]                    \n",
      "                                                                 dense_5[2][0]                    \n",
      "                                                                 dense_5[3][0]                    \n",
      "                                                                 dense_5[4][0]                    \n",
      "                                                                 dense_5[5][0]                    \n",
      "                                                                 dense_5[6][0]                    \n",
      "                                                                 dense_5[7][0]                    \n",
      "                                                                 dense_5[8][0]                    \n",
      "                                                                 dense_5[9][0]                    \n",
      "                                                                 dense_5[10][0]                   \n",
      "                                                                 dense_5[11][0]                   \n",
      "                                                                 dense_5[12][0]                   \n",
      "                                                                 dense_5[13][0]                   \n",
      "                                                                 dense_5[14][0]                   \n",
      "                                                                 dense_5[15][0]                   \n",
      "                                                                 dense_5[16][0]                   \n",
      "                                                                 dense_5[17][0]                   \n",
      "                                                                 dense_5[18][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ss0 (InputLayer)                (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cc0 (InputLayer)                (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 32), (None,  8320        reshape_1[0][0]                  \n",
      "                                                                 ss0[0][0]                        \n",
      "                                                                 cc0[0][0]                        \n",
      "                                                                 reshape_1[1][0]                  \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 reshape_1[2][0]                  \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "                                                                 reshape_1[3][0]                  \n",
      "                                                                 lstm_2[2][0]                     \n",
      "                                                                 lstm_2[2][2]                     \n",
      "                                                                 reshape_1[4][0]                  \n",
      "                                                                 lstm_2[3][0]                     \n",
      "                                                                 lstm_2[3][2]                     \n",
      "                                                                 reshape_1[5][0]                  \n",
      "                                                                 lstm_2[4][0]                     \n",
      "                                                                 lstm_2[4][2]                     \n",
      "                                                                 reshape_1[6][0]                  \n",
      "                                                                 lstm_2[5][0]                     \n",
      "                                                                 lstm_2[5][2]                     \n",
      "                                                                 reshape_1[7][0]                  \n",
      "                                                                 lstm_2[6][0]                     \n",
      "                                                                 lstm_2[6][2]                     \n",
      "                                                                 reshape_1[8][0]                  \n",
      "                                                                 lstm_2[7][0]                     \n",
      "                                                                 lstm_2[7][2]                     \n",
      "                                                                 reshape_1[9][0]                  \n",
      "                                                                 lstm_2[8][0]                     \n",
      "                                                                 lstm_2[8][2]                     \n",
      "                                                                 reshape_1[10][0]                 \n",
      "                                                                 lstm_2[9][0]                     \n",
      "                                                                 lstm_2[9][2]                     \n",
      "                                                                 reshape_1[11][0]                 \n",
      "                                                                 lstm_2[10][0]                    \n",
      "                                                                 lstm_2[10][2]                    \n",
      "                                                                 reshape_1[12][0]                 \n",
      "                                                                 lstm_2[11][0]                    \n",
      "                                                                 lstm_2[11][2]                    \n",
      "                                                                 reshape_1[13][0]                 \n",
      "                                                                 lstm_2[12][0]                    \n",
      "                                                                 lstm_2[12][2]                    \n",
      "                                                                 reshape_1[14][0]                 \n",
      "                                                                 lstm_2[13][0]                    \n",
      "                                                                 lstm_2[13][2]                    \n",
      "                                                                 reshape_1[15][0]                 \n",
      "                                                                 lstm_2[14][0]                    \n",
      "                                                                 lstm_2[14][2]                    \n",
      "                                                                 reshape_1[16][0]                 \n",
      "                                                                 lstm_2[15][0]                    \n",
      "                                                                 lstm_2[15][2]                    \n",
      "                                                                 reshape_1[17][0]                 \n",
      "                                                                 lstm_2[16][0]                    \n",
      "                                                                 lstm_2[16][2]                    \n",
      "                                                                 reshape_1[18][0]                 \n",
      "                                                                 lstm_2[17][0]                    \n",
      "                                                                 lstm_2[17][2]                    \n",
      "                                                                 reshape_1[19][0]                 \n",
      "                                                                 lstm_2[18][0]                    \n",
      "                                                                 lstm_2[18][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 132)          4356        lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[2][0]                     \n",
      "                                                                 lstm_2[3][0]                     \n",
      "                                                                 lstm_2[4][0]                     \n",
      "                                                                 lstm_2[5][0]                     \n",
      "                                                                 lstm_2[6][0]                     \n",
      "                                                                 lstm_2[7][0]                     \n",
      "                                                                 lstm_2[8][0]                     \n",
      "                                                                 lstm_2[9][0]                     \n",
      "                                                                 lstm_2[10][0]                    \n",
      "                                                                 lstm_2[11][0]                    \n",
      "                                                                 lstm_2[12][0]                    \n",
      "                                                                 lstm_2[13][0]                    \n",
      "                                                                 lstm_2[14][0]                    \n",
      "                                                                 lstm_2[15][0]                    \n",
      "                                                                 lstm_2[16][0]                    \n",
      "                                                                 lstm_2[17][0]                    \n",
      "                                                                 lstm_2[18][0]                    \n",
      "                                                                 lstm_2[19][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 132)          0           dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "                                                                 dense_3[2][0]                    \n",
      "                                                                 dense_3[3][0]                    \n",
      "                                                                 dense_3[4][0]                    \n",
      "                                                                 dense_3[5][0]                    \n",
      "                                                                 dense_3[6][0]                    \n",
      "                                                                 dense_3[7][0]                    \n",
      "                                                                 dense_3[8][0]                    \n",
      "                                                                 dense_3[9][0]                    \n",
      "                                                                 dense_3[10][0]                   \n",
      "                                                                 dense_3[11][0]                   \n",
      "                                                                 dense_3[12][0]                   \n",
      "                                                                 dense_3[13][0]                   \n",
      "                                                                 dense_3[14][0]                   \n",
      "                                                                 dense_3[15][0]                   \n",
      "                                                                 dense_3[16][0]                   \n",
      "                                                                 dense_3[17][0]                   \n",
      "                                                                 dense_3[18][0]                   \n",
      "                                                                 dense_3[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           4256        activation_1[0][0]               \n",
      "                                                                 activation_1[1][0]               \n",
      "                                                                 activation_1[2][0]               \n",
      "                                                                 activation_1[3][0]               \n",
      "                                                                 activation_1[4][0]               \n",
      "                                                                 activation_1[5][0]               \n",
      "                                                                 activation_1[6][0]               \n",
      "                                                                 activation_1[7][0]               \n",
      "                                                                 activation_1[8][0]               \n",
      "                                                                 activation_1[9][0]               \n",
      "                                                                 activation_1[10][0]              \n",
      "                                                                 activation_1[11][0]              \n",
      "                                                                 activation_1[12][0]              \n",
      "                                                                 activation_1[13][0]              \n",
      "                                                                 activation_1[14][0]              \n",
      "                                                                 activation_1[15][0]              \n",
      "                                                                 activation_1[16][0]              \n",
      "                                                                 activation_1[17][0]              \n",
      "                                                                 activation_1[18][0]              \n",
      "==================================================================================================\n",
      "Total params: 59,233\n",
      "Trainable params: 52,633\n",
      "Non-trainable params: 6,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import pydot_ng as pydot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import plot_model\n",
    "plot_model(model1, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(y_train_oh_s) (20, 8, 132)\n"
     ]
    }
   ],
   "source": [
    "# Convert and reshape y_train to one-hot vectors \n",
    "\n",
    "y_train_onehot_ = to_categorical(y_train , num_words) \n",
    "y_train_oh_s = (np.array_split(y_train_onehot_, 20, axis=1))\n",
    "for i in range(len(y_train_oh_s)):\n",
    "    y_train_oh_s[i]=y_train_oh_s[i].squeeze()    \n",
    "\n",
    "print(\"np.shape(y_train_oh_s)\",np.shape( y_train_oh_s))\n",
    "\n",
    "# Other entries\n",
    "m=np.shape(x_train)[0]\n",
    "s0 = np.zeros(( m, n_s))\n",
    "c0 = np.zeros(( m, n_s))\n",
    "ss0 = np.zeros(( m, n_a))\n",
    "cc0 = np.zeros(( m, n_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 89.8595 - activation_1_loss_1: 4.1789 - activation_1_loss_2: 4.1510 - activation_1_loss_3: 4.1497 - activation_1_loss_4: 4.1494 - activation_1_loss_5: 4.1494 - activation_1_loss_6: 4.1495 - activation_1_loss_7: 4.2738 - activation_1_loss_8: 4.3982 - activation_1_loss_9: 4.3982 - activation_1_loss_10: 4.3982 - activation_1_loss_11: 4.3981 - activation_1_loss_12: 4.6469 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7712 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7712 - activation_1_loss_18: 4.7712 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 0s - loss: 89.8590 - activation_1_loss_1: 4.1787 - activation_1_loss_2: 4.1509 - activation_1_loss_3: 4.1496 - activation_1_loss_4: 4.1494 - activation_1_loss_5: 4.1494 - activation_1_loss_6: 4.1494 - activation_1_loss_7: 4.2738 - activation_1_loss_8: 4.3982 - activation_1_loss_9: 4.3981 - activation_1_loss_10: 4.3982 - activation_1_loss_11: 4.3981 - activation_1_loss_12: 4.6469 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7712 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7712 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 0s - loss: 89.8585 - activation_1_loss_1: 4.1785 - activation_1_loss_2: 4.1509 - activation_1_loss_3: 4.1496 - activation_1_loss_4: 4.1494 - activation_1_loss_5: 4.1494 - activation_1_loss_6: 4.1494 - activation_1_loss_7: 4.2738 - activation_1_loss_8: 4.3981 - activation_1_loss_9: 4.3981 - activation_1_loss_10: 4.3982 - activation_1_loss_11: 4.3980 - activation_1_loss_12: 4.6469 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7712 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7712 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 0s - loss: 89.8580 - activation_1_loss_1: 4.1783 - activation_1_loss_2: 4.1508 - activation_1_loss_3: 4.1496 - activation_1_loss_4: 4.1493 - activation_1_loss_5: 4.1493 - activation_1_loss_6: 4.1494 - activation_1_loss_7: 4.2737 - activation_1_loss_8: 4.3981 - activation_1_loss_9: 4.3981 - activation_1_loss_10: 4.3981 - activation_1_loss_11: 4.3980 - activation_1_loss_12: 4.6469 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 0s - loss: 89.8575 - activation_1_loss_1: 4.1781 - activation_1_loss_2: 4.1508 - activation_1_loss_3: 4.1495 - activation_1_loss_4: 4.1493 - activation_1_loss_5: 4.1493 - activation_1_loss_6: 4.1493 - activation_1_loss_7: 4.2737 - activation_1_loss_8: 4.3981 - activation_1_loss_9: 4.3981 - activation_1_loss_10: 4.3981 - activation_1_loss_11: 4.3980 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 0s - loss: 89.8570 - activation_1_loss_1: 4.1779 - activation_1_loss_2: 4.1507 - activation_1_loss_3: 4.1495 - activation_1_loss_4: 4.1493 - activation_1_loss_5: 4.1493 - activation_1_loss_6: 4.1493 - activation_1_loss_7: 4.2737 - activation_1_loss_8: 4.3981 - activation_1_loss_9: 4.3981 - activation_1_loss_10: 4.3981 - activation_1_loss_11: 4.3980 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 0s - loss: 89.8565 - activation_1_loss_1: 4.1777 - activation_1_loss_2: 4.1507 - activation_1_loss_3: 4.1495 - activation_1_loss_4: 4.1493 - activation_1_loss_5: 4.1493 - activation_1_loss_6: 4.1493 - activation_1_loss_7: 4.2737 - activation_1_loss_8: 4.3981 - activation_1_loss_9: 4.3980 - activation_1_loss_10: 4.3981 - activation_1_loss_11: 4.3980 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      " - 0s - loss: 89.8560 - activation_1_loss_1: 4.1775 - activation_1_loss_2: 4.1507 - activation_1_loss_3: 4.1494 - activation_1_loss_4: 4.1492 - activation_1_loss_5: 4.1492 - activation_1_loss_6: 4.1493 - activation_1_loss_7: 4.2737 - activation_1_loss_8: 4.3980 - activation_1_loss_9: 4.3980 - activation_1_loss_10: 4.3981 - activation_1_loss_11: 4.3979 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 0s - loss: 89.8555 - activation_1_loss_1: 4.1773 - activation_1_loss_2: 4.1506 - activation_1_loss_3: 4.1494 - activation_1_loss_4: 4.1492 - activation_1_loss_5: 4.1492 - activation_1_loss_6: 4.1492 - activation_1_loss_7: 4.2736 - activation_1_loss_8: 4.3980 - activation_1_loss_9: 4.3980 - activation_1_loss_10: 4.3980 - activation_1_loss_11: 4.3979 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 0s - loss: 89.8551 - activation_1_loss_1: 4.1771 - activation_1_loss_2: 4.1506 - activation_1_loss_3: 4.1494 - activation_1_loss_4: 4.1492 - activation_1_loss_5: 4.1492 - activation_1_loss_6: 4.1492 - activation_1_loss_7: 4.2736 - activation_1_loss_8: 4.3980 - activation_1_loss_9: 4.3980 - activation_1_loss_10: 4.3980 - activation_1_loss_11: 4.3979 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 11/100\n",
      " - 0s - loss: 89.8546 - activation_1_loss_1: 4.1769 - activation_1_loss_2: 4.1506 - activation_1_loss_3: 4.1493 - activation_1_loss_4: 4.1491 - activation_1_loss_5: 4.1491 - activation_1_loss_6: 4.1492 - activation_1_loss_7: 4.2736 - activation_1_loss_8: 4.3980 - activation_1_loss_9: 4.3980 - activation_1_loss_10: 4.3980 - activation_1_loss_11: 4.3979 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 12/100\n",
      " - 0s - loss: 89.8541 - activation_1_loss_1: 4.1767 - activation_1_loss_2: 4.1505 - activation_1_loss_3: 4.1493 - activation_1_loss_4: 4.1491 - activation_1_loss_5: 4.1491 - activation_1_loss_6: 4.1491 - activation_1_loss_7: 4.2736 - activation_1_loss_8: 4.3980 - activation_1_loss_9: 4.3980 - activation_1_loss_10: 4.3980 - activation_1_loss_11: 4.3979 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 13/100\n",
      " - 0s - loss: 89.8537 - activation_1_loss_1: 4.1765 - activation_1_loss_2: 4.1505 - activation_1_loss_3: 4.1493 - activation_1_loss_4: 4.1491 - activation_1_loss_5: 4.1491 - activation_1_loss_6: 4.1491 - activation_1_loss_7: 4.2735 - activation_1_loss_8: 4.3980 - activation_1_loss_9: 4.3979 - activation_1_loss_10: 4.3980 - activation_1_loss_11: 4.3978 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7712 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 14/100\n",
      " - 0s - loss: 89.8532 - activation_1_loss_1: 4.1764 - activation_1_loss_2: 4.1504 - activation_1_loss_3: 4.1493 - activation_1_loss_4: 4.1491 - activation_1_loss_5: 4.1491 - activation_1_loss_6: 4.1491 - activation_1_loss_7: 4.2735 - activation_1_loss_8: 4.3979 - activation_1_loss_9: 4.3979 - activation_1_loss_10: 4.3979 - activation_1_loss_11: 4.3978 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      " - 0s - loss: 89.8528 - activation_1_loss_1: 4.1762 - activation_1_loss_2: 4.1504 - activation_1_loss_3: 4.1492 - activation_1_loss_4: 4.1490 - activation_1_loss_5: 4.1490 - activation_1_loss_6: 4.1491 - activation_1_loss_7: 4.2735 - activation_1_loss_8: 4.3979 - activation_1_loss_9: 4.3979 - activation_1_loss_10: 4.3979 - activation_1_loss_11: 4.3978 - activation_1_loss_12: 4.6468 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 16/100\n",
      " - 0s - loss: 89.8523 - activation_1_loss_1: 4.1760 - activation_1_loss_2: 4.1504 - activation_1_loss_3: 4.1492 - activation_1_loss_4: 4.1490 - activation_1_loss_5: 4.1490 - activation_1_loss_6: 4.1490 - activation_1_loss_7: 4.2735 - activation_1_loss_8: 4.3979 - activation_1_loss_9: 4.3979 - activation_1_loss_10: 4.3979 - activation_1_loss_11: 4.3978 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 17/100\n",
      " - 0s - loss: 89.8519 - activation_1_loss_1: 4.1758 - activation_1_loss_2: 4.1503 - activation_1_loss_3: 4.1492 - activation_1_loss_4: 4.1490 - activation_1_loss_5: 4.1490 - activation_1_loss_6: 4.1490 - activation_1_loss_7: 4.2734 - activation_1_loss_8: 4.3979 - activation_1_loss_9: 4.3979 - activation_1_loss_10: 4.3979 - activation_1_loss_11: 4.3978 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 18/100\n",
      " - 0s - loss: 89.8515 - activation_1_loss_1: 4.1756 - activation_1_loss_2: 4.1503 - activation_1_loss_3: 4.1492 - activation_1_loss_4: 4.1490 - activation_1_loss_5: 4.1490 - activation_1_loss_6: 4.1490 - activation_1_loss_7: 4.2734 - activation_1_loss_8: 4.3979 - activation_1_loss_9: 4.3979 - activation_1_loss_10: 4.3979 - activation_1_loss_11: 4.3978 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 19/100\n",
      " - 0s - loss: 89.8511 - activation_1_loss_1: 4.1755 - activation_1_loss_2: 4.1503 - activation_1_loss_3: 4.1491 - activation_1_loss_4: 4.1489 - activation_1_loss_5: 4.1489 - activation_1_loss_6: 4.1490 - activation_1_loss_7: 4.2734 - activation_1_loss_8: 4.3978 - activation_1_loss_9: 4.3978 - activation_1_loss_10: 4.3979 - activation_1_loss_11: 4.3978 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 20/100\n",
      " - 0s - loss: 89.8506 - activation_1_loss_1: 4.1753 - activation_1_loss_2: 4.1502 - activation_1_loss_3: 4.1491 - activation_1_loss_4: 4.1489 - activation_1_loss_5: 4.1489 - activation_1_loss_6: 4.1489 - activation_1_loss_7: 4.2734 - activation_1_loss_8: 4.3978 - activation_1_loss_9: 4.3978 - activation_1_loss_10: 4.3978 - activation_1_loss_11: 4.3977 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7712 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 21/100\n",
      " - 0s - loss: 89.8502 - activation_1_loss_1: 4.1751 - activation_1_loss_2: 4.1502 - activation_1_loss_3: 4.1491 - activation_1_loss_4: 4.1489 - activation_1_loss_5: 4.1489 - activation_1_loss_6: 4.1489 - activation_1_loss_7: 4.2734 - activation_1_loss_8: 4.3978 - activation_1_loss_9: 4.3978 - activation_1_loss_10: 4.3978 - activation_1_loss_11: 4.3977 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      " - 0s - loss: 89.8498 - activation_1_loss_1: 4.1750 - activation_1_loss_2: 4.1502 - activation_1_loss_3: 4.1490 - activation_1_loss_4: 4.1489 - activation_1_loss_5: 4.1489 - activation_1_loss_6: 4.1489 - activation_1_loss_7: 4.2733 - activation_1_loss_8: 4.3978 - activation_1_loss_9: 4.3978 - activation_1_loss_10: 4.3978 - activation_1_loss_11: 4.3977 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 23/100\n",
      " - 0s - loss: 89.8494 - activation_1_loss_1: 4.1748 - activation_1_loss_2: 4.1501 - activation_1_loss_3: 4.1490 - activation_1_loss_4: 4.1488 - activation_1_loss_5: 4.1488 - activation_1_loss_6: 4.1489 - activation_1_loss_7: 4.2733 - activation_1_loss_8: 4.3978 - activation_1_loss_9: 4.3978 - activation_1_loss_10: 4.3978 - activation_1_loss_11: 4.3977 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7712 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 24/100\n",
      " - 0s - loss: 89.8490 - activation_1_loss_1: 4.1746 - activation_1_loss_2: 4.1501 - activation_1_loss_3: 4.1490 - activation_1_loss_4: 4.1488 - activation_1_loss_5: 4.1488 - activation_1_loss_6: 4.1488 - activation_1_loss_7: 4.2733 - activation_1_loss_8: 4.3978 - activation_1_loss_9: 4.3978 - activation_1_loss_10: 4.3978 - activation_1_loss_11: 4.3977 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 25/100\n",
      " - 0s - loss: 89.8486 - activation_1_loss_1: 4.1745 - activation_1_loss_2: 4.1501 - activation_1_loss_3: 4.1490 - activation_1_loss_4: 4.1488 - activation_1_loss_5: 4.1488 - activation_1_loss_6: 4.1488 - activation_1_loss_7: 4.2733 - activation_1_loss_8: 4.3978 - activation_1_loss_9: 4.3977 - activation_1_loss_10: 4.3978 - activation_1_loss_11: 4.3977 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 26/100\n",
      " - 0s - loss: 89.8482 - activation_1_loss_1: 4.1743 - activation_1_loss_2: 4.1500 - activation_1_loss_3: 4.1489 - activation_1_loss_4: 4.1488 - activation_1_loss_5: 4.1488 - activation_1_loss_6: 4.1488 - activation_1_loss_7: 4.2733 - activation_1_loss_8: 4.3977 - activation_1_loss_9: 4.3977 - activation_1_loss_10: 4.3977 - activation_1_loss_11: 4.3976 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 27/100\n",
      " - 0s - loss: 89.8479 - activation_1_loss_1: 4.1741 - activation_1_loss_2: 4.1500 - activation_1_loss_3: 4.1489 - activation_1_loss_4: 4.1487 - activation_1_loss_5: 4.1487 - activation_1_loss_6: 4.1488 - activation_1_loss_7: 4.2732 - activation_1_loss_8: 4.3977 - activation_1_loss_9: 4.3977 - activation_1_loss_10: 4.3977 - activation_1_loss_11: 4.3976 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 28/100\n",
      " - 0s - loss: 89.8475 - activation_1_loss_1: 4.1740 - activation_1_loss_2: 4.1500 - activation_1_loss_3: 4.1489 - activation_1_loss_4: 4.1487 - activation_1_loss_5: 4.1487 - activation_1_loss_6: 4.1487 - activation_1_loss_7: 4.2732 - activation_1_loss_8: 4.3977 - activation_1_loss_9: 4.3977 - activation_1_loss_10: 4.3977 - activation_1_loss_11: 4.3976 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      " - 0s - loss: 89.8471 - activation_1_loss_1: 4.1738 - activation_1_loss_2: 4.1499 - activation_1_loss_3: 4.1489 - activation_1_loss_4: 4.1487 - activation_1_loss_5: 4.1487 - activation_1_loss_6: 4.1487 - activation_1_loss_7: 4.2732 - activation_1_loss_8: 4.3977 - activation_1_loss_9: 4.3977 - activation_1_loss_10: 4.3977 - activation_1_loss_11: 4.3976 - activation_1_loss_12: 4.6467 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 30/100\n",
      " - 0s - loss: 89.8467 - activation_1_loss_1: 4.1737 - activation_1_loss_2: 4.1499 - activation_1_loss_3: 4.1489 - activation_1_loss_4: 4.1487 - activation_1_loss_5: 4.1487 - activation_1_loss_6: 4.1487 - activation_1_loss_7: 4.2732 - activation_1_loss_8: 4.3977 - activation_1_loss_9: 4.3977 - activation_1_loss_10: 4.3977 - activation_1_loss_11: 4.3976 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 31/100\n",
      " - 0s - loss: 89.8463 - activation_1_loss_1: 4.1735 - activation_1_loss_2: 4.1499 - activation_1_loss_3: 4.1488 - activation_1_loss_4: 4.1487 - activation_1_loss_5: 4.1486 - activation_1_loss_6: 4.1487 - activation_1_loss_7: 4.2732 - activation_1_loss_8: 4.3977 - activation_1_loss_9: 4.3977 - activation_1_loss_10: 4.3977 - activation_1_loss_11: 4.3976 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 32/100\n",
      " - 0s - loss: 89.8460 - activation_1_loss_1: 4.1734 - activation_1_loss_2: 4.1498 - activation_1_loss_3: 4.1488 - activation_1_loss_4: 4.1486 - activation_1_loss_5: 4.1486 - activation_1_loss_6: 4.1487 - activation_1_loss_7: 4.2732 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3976 - activation_1_loss_10: 4.3977 - activation_1_loss_11: 4.3976 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 33/100\n",
      " - 0s - loss: 89.8456 - activation_1_loss_1: 4.1732 - activation_1_loss_2: 4.1498 - activation_1_loss_3: 4.1488 - activation_1_loss_4: 4.1486 - activation_1_loss_5: 4.1486 - activation_1_loss_6: 4.1486 - activation_1_loss_7: 4.2731 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3976 - activation_1_loss_10: 4.3976 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 34/100\n",
      " - 0s - loss: 89.8452 - activation_1_loss_1: 4.1731 - activation_1_loss_2: 4.1498 - activation_1_loss_3: 4.1488 - activation_1_loss_4: 4.1486 - activation_1_loss_5: 4.1486 - activation_1_loss_6: 4.1486 - activation_1_loss_7: 4.2731 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3976 - activation_1_loss_10: 4.3976 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 35/100\n",
      " - 0s - loss: 89.8449 - activation_1_loss_1: 4.1729 - activation_1_loss_2: 4.1498 - activation_1_loss_3: 4.1487 - activation_1_loss_4: 4.1486 - activation_1_loss_5: 4.1486 - activation_1_loss_6: 4.1486 - activation_1_loss_7: 4.2731 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3976 - activation_1_loss_10: 4.3976 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      " - 0s - loss: 89.8446 - activation_1_loss_1: 4.1728 - activation_1_loss_2: 4.1497 - activation_1_loss_3: 4.1487 - activation_1_loss_4: 4.1485 - activation_1_loss_5: 4.1485 - activation_1_loss_6: 4.1486 - activation_1_loss_7: 4.2731 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3976 - activation_1_loss_10: 4.3976 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7711 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 37/100\n",
      " - 0s - loss: 89.8442 - activation_1_loss_1: 4.1726 - activation_1_loss_2: 4.1497 - activation_1_loss_3: 4.1487 - activation_1_loss_4: 4.1485 - activation_1_loss_5: 4.1485 - activation_1_loss_6: 4.1485 - activation_1_loss_7: 4.2731 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3976 - activation_1_loss_10: 4.3976 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7711 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 38/100\n",
      " - 0s - loss: 89.8439 - activation_1_loss_1: 4.1725 - activation_1_loss_2: 4.1497 - activation_1_loss_3: 4.1487 - activation_1_loss_4: 4.1485 - activation_1_loss_5: 4.1485 - activation_1_loss_6: 4.1485 - activation_1_loss_7: 4.2730 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3976 - activation_1_loss_10: 4.3976 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7711 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 39/100\n",
      " - 0s - loss: 89.8435 - activation_1_loss_1: 4.1723 - activation_1_loss_2: 4.1496 - activation_1_loss_3: 4.1487 - activation_1_loss_4: 4.1485 - activation_1_loss_5: 4.1485 - activation_1_loss_6: 4.1485 - activation_1_loss_7: 4.2730 - activation_1_loss_8: 4.3976 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3976 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 40/100\n",
      " - 0s - loss: 89.8432 - activation_1_loss_1: 4.1722 - activation_1_loss_2: 4.1496 - activation_1_loss_3: 4.1486 - activation_1_loss_4: 4.1485 - activation_1_loss_5: 4.1485 - activation_1_loss_6: 4.1485 - activation_1_loss_7: 4.2730 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3975 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 41/100\n",
      " - 0s - loss: 89.8429 - activation_1_loss_1: 4.1720 - activation_1_loss_2: 4.1496 - activation_1_loss_3: 4.1486 - activation_1_loss_4: 4.1484 - activation_1_loss_5: 4.1484 - activation_1_loss_6: 4.1485 - activation_1_loss_7: 4.2730 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 42/100\n",
      " - 0s - loss: 89.8425 - activation_1_loss_1: 4.1719 - activation_1_loss_2: 4.1496 - activation_1_loss_3: 4.1486 - activation_1_loss_4: 4.1484 - activation_1_loss_5: 4.1484 - activation_1_loss_6: 4.1484 - activation_1_loss_7: 4.2730 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      " - 0s - loss: 89.8422 - activation_1_loss_1: 4.1718 - activation_1_loss_2: 4.1495 - activation_1_loss_3: 4.1486 - activation_1_loss_4: 4.1484 - activation_1_loss_5: 4.1484 - activation_1_loss_6: 4.1484 - activation_1_loss_7: 4.2730 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 44/100\n",
      " - 0s - loss: 89.8419 - activation_1_loss_1: 4.1716 - activation_1_loss_2: 4.1495 - activation_1_loss_3: 4.1486 - activation_1_loss_4: 4.1484 - activation_1_loss_5: 4.1484 - activation_1_loss_6: 4.1484 - activation_1_loss_7: 4.2730 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 45/100\n",
      " - 0s - loss: 89.8416 - activation_1_loss_1: 4.1715 - activation_1_loss_2: 4.1495 - activation_1_loss_3: 4.1485 - activation_1_loss_4: 4.1484 - activation_1_loss_5: 4.1484 - activation_1_loss_6: 4.1484 - activation_1_loss_7: 4.2729 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6466 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 46/100\n",
      " - 0s - loss: 89.8412 - activation_1_loss_1: 4.1714 - activation_1_loss_2: 4.1495 - activation_1_loss_3: 4.1485 - activation_1_loss_4: 4.1484 - activation_1_loss_5: 4.1483 - activation_1_loss_6: 4.1484 - activation_1_loss_7: 4.2729 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3975 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 47/100\n",
      " - 0s - loss: 89.8409 - activation_1_loss_1: 4.1712 - activation_1_loss_2: 4.1494 - activation_1_loss_3: 4.1485 - activation_1_loss_4: 4.1483 - activation_1_loss_5: 4.1483 - activation_1_loss_6: 4.1484 - activation_1_loss_7: 4.2729 - activation_1_loss_8: 4.3975 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3975 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 48/100\n",
      " - 0s - loss: 89.8406 - activation_1_loss_1: 4.1711 - activation_1_loss_2: 4.1494 - activation_1_loss_3: 4.1485 - activation_1_loss_4: 4.1483 - activation_1_loss_5: 4.1483 - activation_1_loss_6: 4.1483 - activation_1_loss_7: 4.2729 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 49/100\n",
      " - 0s - loss: 89.8403 - activation_1_loss_1: 4.1710 - activation_1_loss_2: 4.1494 - activation_1_loss_3: 4.1485 - activation_1_loss_4: 4.1483 - activation_1_loss_5: 4.1483 - activation_1_loss_6: 4.1483 - activation_1_loss_7: 4.2729 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3974 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      " - 0s - loss: 89.8400 - activation_1_loss_1: 4.1708 - activation_1_loss_2: 4.1494 - activation_1_loss_3: 4.1484 - activation_1_loss_4: 4.1483 - activation_1_loss_5: 4.1483 - activation_1_loss_6: 4.1483 - activation_1_loss_7: 4.2729 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7711 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 51/100\n",
      " - 0s - loss: 89.8397 - activation_1_loss_1: 4.1707 - activation_1_loss_2: 4.1493 - activation_1_loss_3: 4.1484 - activation_1_loss_4: 4.1483 - activation_1_loss_5: 4.1483 - activation_1_loss_6: 4.1483 - activation_1_loss_7: 4.2728 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 52/100\n",
      " - 0s - loss: 89.8394 - activation_1_loss_1: 4.1706 - activation_1_loss_2: 4.1493 - activation_1_loss_3: 4.1484 - activation_1_loss_4: 4.1482 - activation_1_loss_5: 4.1482 - activation_1_loss_6: 4.1483 - activation_1_loss_7: 4.2728 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 53/100\n",
      " - 0s - loss: 89.8391 - activation_1_loss_1: 4.1705 - activation_1_loss_2: 4.1493 - activation_1_loss_3: 4.1484 - activation_1_loss_4: 4.1482 - activation_1_loss_5: 4.1482 - activation_1_loss_6: 4.1482 - activation_1_loss_7: 4.2728 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 54/100\n",
      " - 0s - loss: 89.8388 - activation_1_loss_1: 4.1703 - activation_1_loss_2: 4.1493 - activation_1_loss_3: 4.1484 - activation_1_loss_4: 4.1482 - activation_1_loss_5: 4.1482 - activation_1_loss_6: 4.1482 - activation_1_loss_7: 4.2728 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 55/100\n",
      " - 0s - loss: 89.8386 - activation_1_loss_1: 4.1702 - activation_1_loss_2: 4.1492 - activation_1_loss_3: 4.1483 - activation_1_loss_4: 4.1482 - activation_1_loss_5: 4.1482 - activation_1_loss_6: 4.1482 - activation_1_loss_7: 4.2728 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3974 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 56/100\n",
      " - 0s - loss: 89.8383 - activation_1_loss_1: 4.1701 - activation_1_loss_2: 4.1492 - activation_1_loss_3: 4.1483 - activation_1_loss_4: 4.1482 - activation_1_loss_5: 4.1482 - activation_1_loss_6: 4.1482 - activation_1_loss_7: 4.2728 - activation_1_loss_8: 4.3974 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3974 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      " - 0s - loss: 89.8380 - activation_1_loss_1: 4.1700 - activation_1_loss_2: 4.1492 - activation_1_loss_3: 4.1483 - activation_1_loss_4: 4.1482 - activation_1_loss_5: 4.1482 - activation_1_loss_6: 4.1482 - activation_1_loss_7: 4.2728 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 58/100\n",
      " - 0s - loss: 89.8377 - activation_1_loss_1: 4.1698 - activation_1_loss_2: 4.1492 - activation_1_loss_3: 4.1483 - activation_1_loss_4: 4.1481 - activation_1_loss_5: 4.1481 - activation_1_loss_6: 4.1482 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3973 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7711 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 59/100\n",
      " - 0s - loss: 89.8374 - activation_1_loss_1: 4.1697 - activation_1_loss_2: 4.1492 - activation_1_loss_3: 4.1483 - activation_1_loss_4: 4.1481 - activation_1_loss_5: 4.1481 - activation_1_loss_6: 4.1482 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 60/100\n",
      " - 0s - loss: 89.8372 - activation_1_loss_1: 4.1696 - activation_1_loss_2: 4.1491 - activation_1_loss_3: 4.1483 - activation_1_loss_4: 4.1481 - activation_1_loss_5: 4.1481 - activation_1_loss_6: 4.1481 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 61/100\n",
      " - 0s - loss: 89.8369 - activation_1_loss_1: 4.1695 - activation_1_loss_2: 4.1491 - activation_1_loss_3: 4.1482 - activation_1_loss_4: 4.1481 - activation_1_loss_5: 4.1481 - activation_1_loss_6: 4.1481 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 62/100\n",
      " - 0s - loss: 89.8366 - activation_1_loss_1: 4.1694 - activation_1_loss_2: 4.1491 - activation_1_loss_3: 4.1482 - activation_1_loss_4: 4.1481 - activation_1_loss_5: 4.1481 - activation_1_loss_6: 4.1481 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7711 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8956 - activation_1_loss_20: 4.8956 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 63/100\n",
      " - 0s - loss: 89.8364 - activation_1_loss_1: 4.1693 - activation_1_loss_2: 4.1491 - activation_1_loss_3: 4.1482 - activation_1_loss_4: 4.1481 - activation_1_loss_5: 4.1481 - activation_1_loss_6: 4.1481 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      " - 0s - loss: 89.8361 - activation_1_loss_1: 4.1691 - activation_1_loss_2: 4.1490 - activation_1_loss_3: 4.1482 - activation_1_loss_4: 4.1481 - activation_1_loss_5: 4.1481 - activation_1_loss_6: 4.1481 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3973 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6465 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 65/100\n",
      " - 0s - loss: 89.8358 - activation_1_loss_1: 4.1690 - activation_1_loss_2: 4.1490 - activation_1_loss_3: 4.1482 - activation_1_loss_4: 4.1480 - activation_1_loss_5: 4.1480 - activation_1_loss_6: 4.1481 - activation_1_loss_7: 4.2727 - activation_1_loss_8: 4.3973 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 66/100\n",
      " - 0s - loss: 89.8356 - activation_1_loss_1: 4.1689 - activation_1_loss_2: 4.1490 - activation_1_loss_3: 4.1482 - activation_1_loss_4: 4.1480 - activation_1_loss_5: 4.1480 - activation_1_loss_6: 4.1480 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3973 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 67/100\n",
      " - 0s - loss: 89.8353 - activation_1_loss_1: 4.1688 - activation_1_loss_2: 4.1490 - activation_1_loss_3: 4.1482 - activation_1_loss_4: 4.1480 - activation_1_loss_5: 4.1480 - activation_1_loss_6: 4.1480 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 68/100\n",
      " - 0s - loss: 89.8351 - activation_1_loss_1: 4.1687 - activation_1_loss_2: 4.1490 - activation_1_loss_3: 4.1481 - activation_1_loss_4: 4.1480 - activation_1_loss_5: 4.1480 - activation_1_loss_6: 4.1480 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 69/100\n",
      " - 0s - loss: 89.8348 - activation_1_loss_1: 4.1686 - activation_1_loss_2: 4.1489 - activation_1_loss_3: 4.1481 - activation_1_loss_4: 4.1480 - activation_1_loss_5: 4.1480 - activation_1_loss_6: 4.1480 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3972 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 70/100\n",
      " - 0s - loss: 89.8346 - activation_1_loss_1: 4.1685 - activation_1_loss_2: 4.1489 - activation_1_loss_3: 4.1481 - activation_1_loss_4: 4.1480 - activation_1_loss_5: 4.1480 - activation_1_loss_6: 4.1480 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      " - 0s - loss: 89.8343 - activation_1_loss_1: 4.1684 - activation_1_loss_2: 4.1489 - activation_1_loss_3: 4.1481 - activation_1_loss_4: 4.1480 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1480 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 72/100\n",
      " - 0s - loss: 89.8341 - activation_1_loss_1: 4.1683 - activation_1_loss_2: 4.1489 - activation_1_loss_3: 4.1481 - activation_1_loss_4: 4.1479 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1480 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 73/100\n",
      " - 0s - loss: 89.8338 - activation_1_loss_1: 4.1682 - activation_1_loss_2: 4.1489 - activation_1_loss_3: 4.1481 - activation_1_loss_4: 4.1479 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1479 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 74/100\n",
      " - 0s - loss: 89.8336 - activation_1_loss_1: 4.1681 - activation_1_loss_2: 4.1489 - activation_1_loss_3: 4.1480 - activation_1_loss_4: 4.1479 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1479 - activation_1_loss_7: 4.2726 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 75/100\n",
      " - 0s - loss: 89.8334 - activation_1_loss_1: 4.1679 - activation_1_loss_2: 4.1488 - activation_1_loss_3: 4.1480 - activation_1_loss_4: 4.1479 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1479 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3972 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 76/100\n",
      " - 0s - loss: 89.8331 - activation_1_loss_1: 4.1678 - activation_1_loss_2: 4.1488 - activation_1_loss_3: 4.1480 - activation_1_loss_4: 4.1479 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1479 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3972 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 77/100\n",
      " - 0s - loss: 89.8329 - activation_1_loss_1: 4.1677 - activation_1_loss_2: 4.1488 - activation_1_loss_3: 4.1480 - activation_1_loss_4: 4.1479 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1479 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3972 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      " - 0s - loss: 89.8327 - activation_1_loss_1: 4.1676 - activation_1_loss_2: 4.1488 - activation_1_loss_3: 4.1480 - activation_1_loss_4: 4.1479 - activation_1_loss_5: 4.1479 - activation_1_loss_6: 4.1479 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 79/100\n",
      " - 0s - loss: 89.8324 - activation_1_loss_1: 4.1675 - activation_1_loss_2: 4.1488 - activation_1_loss_3: 4.1480 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1479 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 80/100\n",
      " - 0s - loss: 89.8322 - activation_1_loss_1: 4.1674 - activation_1_loss_2: 4.1487 - activation_1_loss_3: 4.1480 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3971 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 81/100\n",
      " - 0s - loss: 89.8320 - activation_1_loss_1: 4.1673 - activation_1_loss_2: 4.1487 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 82/100\n",
      " - 0s - loss: 89.8317 - activation_1_loss_1: 4.1672 - activation_1_loss_2: 4.1487 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 83/100\n",
      " - 0s - loss: 89.8315 - activation_1_loss_1: 4.1671 - activation_1_loss_2: 4.1487 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2725 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 84/100\n",
      " - 0s - loss: 89.8313 - activation_1_loss_1: 4.1670 - activation_1_loss_2: 4.1487 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      " - 0s - loss: 89.8311 - activation_1_loss_1: 4.1670 - activation_1_loss_2: 4.1487 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 86/100\n",
      " - 0s - loss: 89.8309 - activation_1_loss_1: 4.1669 - activation_1_loss_2: 4.1486 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1478 - activation_1_loss_5: 4.1478 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 87/100\n",
      " - 0s - loss: 89.8307 - activation_1_loss_1: 4.1668 - activation_1_loss_2: 4.1486 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1478 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3971 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 88/100\n",
      " - 0s - loss: 89.8304 - activation_1_loss_1: 4.1667 - activation_1_loss_2: 4.1486 - activation_1_loss_3: 4.1479 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3971 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 89/100\n",
      " - 0s - loss: 89.8302 - activation_1_loss_1: 4.1666 - activation_1_loss_2: 4.1486 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3971 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6464 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 90/100\n",
      " - 0s - loss: 89.8300 - activation_1_loss_1: 4.1665 - activation_1_loss_2: 4.1486 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 91/100\n",
      " - 0s - loss: 89.8298 - activation_1_loss_1: 4.1664 - activation_1_loss_2: 4.1486 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      " - 0s - loss: 89.8296 - activation_1_loss_1: 4.1663 - activation_1_loss_2: 4.1485 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 93/100\n",
      " - 0s - loss: 89.8294 - activation_1_loss_1: 4.1662 - activation_1_loss_2: 4.1485 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2724 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 94/100\n",
      " - 0s - loss: 89.8292 - activation_1_loss_1: 4.1661 - activation_1_loss_2: 4.1485 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1477 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2723 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3970 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 95/100\n",
      " - 0s - loss: 89.8290 - activation_1_loss_1: 4.1660 - activation_1_loss_2: 4.1485 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1477 - activation_1_loss_5: 4.1476 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2723 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3969 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7710 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 96/100\n",
      " - 0s - loss: 89.8288 - activation_1_loss_1: 4.1659 - activation_1_loss_2: 4.1485 - activation_1_loss_3: 4.1478 - activation_1_loss_4: 4.1476 - activation_1_loss_5: 4.1476 - activation_1_loss_6: 4.1477 - activation_1_loss_7: 4.2723 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3969 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7709 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 97/100\n",
      " - 0s - loss: 89.8286 - activation_1_loss_1: 4.1659 - activation_1_loss_2: 4.1485 - activation_1_loss_3: 4.1477 - activation_1_loss_4: 4.1476 - activation_1_loss_5: 4.1476 - activation_1_loss_6: 4.1476 - activation_1_loss_7: 4.2723 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3969 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7710 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7709 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 98/100\n",
      " - 0s - loss: 89.8284 - activation_1_loss_1: 4.1658 - activation_1_loss_2: 4.1484 - activation_1_loss_3: 4.1477 - activation_1_loss_4: 4.1476 - activation_1_loss_5: 4.1476 - activation_1_loss_6: 4.1476 - activation_1_loss_7: 4.2723 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3969 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7709 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7710 - activation_1_loss_18: 4.7709 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      " - 0s - loss: 89.8282 - activation_1_loss_1: 4.1657 - activation_1_loss_2: 4.1484 - activation_1_loss_3: 4.1477 - activation_1_loss_4: 4.1476 - activation_1_loss_5: 4.1476 - activation_1_loss_6: 4.1476 - activation_1_loss_7: 4.2723 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3969 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7709 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7709 - activation_1_loss_18: 4.7709 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n",
      "Epoch 100/100\n",
      " - 0s - loss: 89.8280 - activation_1_loss_1: 4.1656 - activation_1_loss_2: 4.1484 - activation_1_loss_3: 4.1477 - activation_1_loss_4: 4.1476 - activation_1_loss_5: 4.1476 - activation_1_loss_6: 4.1476 - activation_1_loss_7: 4.2723 - activation_1_loss_8: 4.3970 - activation_1_loss_9: 4.3970 - activation_1_loss_10: 4.3970 - activation_1_loss_11: 4.3969 - activation_1_loss_12: 4.6463 - activation_1_loss_13: 4.7710 - activation_1_loss_14: 4.7709 - activation_1_loss_15: 4.7710 - activation_1_loss_16: 4.7710 - activation_1_loss_17: 4.7709 - activation_1_loss_18: 4.7709 - activation_1_loss_19: 4.8957 - activation_1_loss_20: 4.8957 - activation_1_acc_1: 0.7500 - activation_1_acc_2: 0.7500 - activation_1_acc_3: 0.7500 - activation_1_acc_4: 0.7500 - activation_1_acc_5: 0.7500 - activation_1_acc_6: 0.7500 - activation_1_acc_7: 0.6250 - activation_1_acc_8: 0.5000 - activation_1_acc_9: 0.5000 - activation_1_acc_10: 0.5000 - activation_1_acc_11: 0.5000 - activation_1_acc_12: 0.2500 - activation_1_acc_13: 0.1250 - activation_1_acc_14: 0.1250 - activation_1_acc_15: 0.1250 - activation_1_acc_16: 0.1250 - activation_1_acc_17: 0.1250 - activation_1_acc_18: 0.1250 - activation_1_acc_19: 0.0000e+00 - activation_1_acc_20: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e104168ba8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit([x_train, s0,c0, ss0, cc0], list(y_train_oh_s), verbose=2, epochs = 100 , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(y_val_oh_s) (20, 2, 132)\n"
     ]
    }
   ],
   "source": [
    "# Convert and reshape y_val to one-hot vectors \n",
    "\n",
    "y_val_onehot_ = to_categorical(y_val , num_words)\n",
    "y_val_oh_s = (np.array_split(y_val_onehot_, 20, axis=1))  \n",
    "for i in range(len(y_val_oh_s)):\n",
    "    y_val_oh_s[i]=y_val_oh_s[i].squeeze()\n",
    "    \n",
    "print(\"np.shape(y_val_oh_s)\",np.shape( y_val_oh_s))\n",
    "\n",
    "# Other entries\n",
    "me=np.shape(x_val)[0]\n",
    "s0e = np.zeros(( me, n_s))\n",
    "c0e = np.zeros(( me, n_s))\n",
    "ss0e = np.zeros(( me, n_a))\n",
    "cc0e = np.zeros(( me, n_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step\n",
      "Test accuracy =  [85.47127532958984, 3.9225215911865234, 3.899397611618042, 3.8983757495880127, 3.8982574939727783, 3.8982410430908203, 3.8982388973236084, 3.89823842048645, 3.89823842048645, 3.89823842048645, 3.89823842048645, 3.89823842048645, 4.396964073181152, 4.396968364715576, 4.396964073181152, 4.895694732666016, 4.895691871643066, 4.895695686340332, 4.895693778991699, 4.895683288574219, 4.895693778991699, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "loss = model1.evaluate([x_val, s0e,c0e, ss0e, cc0e], y_val_oh_s)\n",
    "\n",
    "print(\"Test accuracy = \", loss)\n",
    "#print(\"model.metrics_names\", model1.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model1.predict([x_val, s0e,c0e, ss0e, cc0e], batch_size=1, verbose=1, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
